{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ ФИВТ: Курс Машинное Обучение (осень, 2016), Арсений Ашуха, ars.ashuha@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Check Questions</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 1**: Зачем нужно структурное предсказание?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    ">Чтобы предсказывать не одну переменную, а несколько взаимосвязанных: последовательность, набор классов, матрицу, дерево.\n",
    "\n",
    "**Вопрос 2**: Что такое сопряженное распределение?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    ">Распределения $p(\\theta) \\sim A(\\alpha_{0})$ и $p(x|\\theta)\\sim B(\\beta)$ -- называются сопряженными, если выполняется $p(\\theta|x) \\sim A(\\alpha_{1})$\n",
    "\n",
    "\n",
    "**Вопрос 3**: Какое распределение сопряженное к равномерному, докажите?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    ">$P(X|\\theta) = \\frac{1}{\\theta^n} \\cdot I(0 \\leq x_1,...,x_n \\leq \\theta)$ -- равномерное распределение.\n",
    "\n",
    ">Далее убедимся, что сопряженным распределением является распределение Парето:\n",
    "Пусть $P(\\theta | a,b) = I(\\theta \\geq a) \\frac{ba^b}{\\theta^{b+1}}$, \n",
    "тогда $P(X|\\theta) \\cdot P(\\theta|a,b) = I(X_{(n)} \\leq \\theta, a \\leq \\theta)\\frac{1}{\\theta^n} \\frac{1}{\\theta^{b+1}} \\cdot const = I(max(X_{(n)},a) \\leq \\theta) \\frac{1}{\\theta^{b+1 + n}} \\cdot const,$\n",
    "\n",
    "\n",
    "\n",
    "**Вопрос 4**: В чем заключается Байесовский подход к машинному обучению?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "> Суть в ином подходе к теории вероятностей в применении к машинному обучению.\n",
    "> Вероятность считается мерой незнания, все величины считаются случайными, т.е. имеющими вероятность.\n",
    "Формула Байеса является ключевым инструментом в данном подходе.\n",
    "> Оценки неизвестных параметров -- апостериорные распределения. Т.е. мы пытаемся найти смесь распределений, наиболее хорошо описывающих данные.\n",
    "\n",
    "\n",
    "**Вопрос 5**: В чем основные преимущества Байесовского подхода к машинному обучения?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "> Мы получаем на выходе распределение и можем сделать точные байесовские оценки, основываясь на этом самом апостериорном распределении.\n",
    "Т.е. мы можем сказать насколько мы уверены в том ответе, который мы выдаем. Мы можем находить доверительные интервалы и прочие статистические величины считать по этим полученным распределениям.\n",
    "\n",
    "\n",
    "**Вопрос 6**: Чем отличается структурный метод опорных векторов от неструктурного, в чем сложности при обучении структурного?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "\n",
    ">S-SVM позволяет выдавать не просто метку класса или регрессионное предсказание, S-SVM может выдать структуру. Одну среди множества других структур. Отличие также в том, что в обычном SVM мы максимизируем такую функцию $<w, \\psi(x)y>$, в S-SVM - $<w, \\psi(x,y)>$.\n",
    "Где $\\psi$ - некоторая функция. Именно то, как подобрать эту функцию и является центральной частью построения S-SVM. И это может быть довольно сложной задачей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Task</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим задачу построения коллажа из нескольких изображений, к примеру несколько фотографий группы людей, на каждой кто-то отвернулся или моргнул ... Вы хотите получить одну фотографию, на которой все получились хорошо. На вход поступает K изображений а на выходе вам нужно выдать матрицу размером с изображение, где в каждом пикселе будет указано из какой картинки вам нужно его взять. Вы хотите сделать фотографию так, чтобы места склейки были незаметны. \n",
    "\n",
    "- Введите граф модель, почему вы выбрали именно такую, приложите рисунок\n",
    "- Потенциалы каких порядков вы собираетесь использовать? \n",
    "- Определите потенциалы -- какой в них физический смысл? почему они поощряют незаметные склеивания?\n",
    "- Предложить несколько вариантов выбора потенциалов.\n",
    "\n",
    "![](ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Решение>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. > Выбор пал на MRF. Если честно, потому что вот: http://www.machinelearning.ru/wiki/images/d/db/GM16_assignment2.pdf\n",
    "> Но все объясняется еще и тем, что марковские сети в отличие от байесовских могут быть циклическими и неориентированными графами, что пригодно для их применения на картинках, где связи между пикселями ненаправленные и могут быть очень разными (циклическая модель тоже возможна).\n",
    ">Модель MRF может иметь разную структуру.\n",
    "![](./img_task/graph_models.png)\n",
    "\n",
    "Картинка взята отсюда: https://mitpress.mit.edu/sites/default/files/titles/content/9780262015776_sch_0001.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 \n",
    "> Опять же, ссылаясь на http://www.machinelearning.ru/wiki/images/d/db/GM16_assignment2.pdf                       Мы берем потенциалы первого и второго порядка по приведенной ниже формуле.\n",
    "\n",
    "![](./img_task/mrf.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\n",
    "> Про физический смысл.\n",
    "* Потенциалы первого порядка [или унарные потенциалы] показывают насколько данному пикселю свойственна принадлежность к определенному классу.\n",
    "* Потенциалы второго порядка [или бинарные потенциалы] показывают вероятность наличие такой пары меток у данных двух пикселей.\n",
    "\n",
    ">Таким образом бинарные потенциалы дают некий штраф за выбор двух разных классов у соседних пикселей. Именно этим обосновывается гладкость склейки.\n",
    "\n",
    "link: http://www.machinelearning.ru/wiki/images/6/61/MRFtutorial2.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\n",
    "> Про способы выбора унарных и бинарных потенциалов также написано тут: http://www.machinelearning.ru/wiki/images/6/61/MRFtutorial2.pdf\n",
    "\n",
    ">Для унарного потенциала:\n",
    "1. Цветовая модель - показывает насколько появление тех или иных цветов более вероятно в данном классе\n",
    "2. Позиционная модель - показывает априорные предположения о положении данного класса на изображении. Т.е. насколько данный класс вероятен в данной части изображения\n",
    "3. Текстурная модель - показывает насколько текстура окрестности пикселя вероятна для данного пикселя\n",
    "\n",
    ">Для бинарных потенциалов:\n",
    "1. Модель Поттса: штраф за несовпадение классов соседних пикселей. Т.е. мы не учитываем, для каких конкретно пикселей изображения мы считаем потенциал, нам важны лишь их классы $\\ \\ \\theta_{ij}(x_i, x_j) = 1 - \\delta(x_i, x_j)$\n",
    "2. Штраф за несовпадение классов с учетом контраста $\\ \\ \\theta_{ij}(x_i,x_j)=exp\\left(\\frac{-(x_i-x_j)^2}{2 \\sigma^2}\\right)(1-\\delta(x_i,x_j))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\">Bonus part: Semantic Image Segmentation</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Если вы, хотите разобраться с граф моделями -- попробуйте реализовать это на питон, выполнение займет около 30-40 часов, на щедрые бонусные баллы (3-5 баллов) -- можно обсудить заранее. Если решитесь, напишите мне. \n",
    "\n",
    "http://www.machinelearning.ru/wiki/index.php?title=Графические_модели_(курс_лекций)/2012/Задание_5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
